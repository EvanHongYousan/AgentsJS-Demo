/**
 * ç¤ºä¾‹ 1: åŸºç¡€ Agent
 * å±•ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªæœ€ç®€å•çš„ AI Agent
 */

import { initializeAgentExecutorWithOptions } from "langchain/agents";
import { getModel, showModelConfig } from "../config/model-config.js";

async function runBasicAgent() {
  console.log("ğŸ¤– ç¤ºä¾‹ 1: åŸºç¡€ Agent\n");
  console.log("=" .repeat(50));

  // æ˜¾ç¤ºå½“å‰æ¨¡å‹é…ç½®
  showModelConfig();

  // 1. åˆå§‹åŒ–è¯­è¨€æ¨¡å‹ï¼ˆè‡ªåŠ¨æ ¹æ®ç¯å¢ƒå˜é‡é€‰æ‹© OpenAI æˆ– OpenRouterï¼‰
  const model = getModel({ temperature: 0.7 });

  // 2. åˆ›å»º Agent (æ— å·¥å…·ç‰ˆæœ¬)
  const agent = await initializeAgentExecutorWithOptions(
    [], // ç©ºå·¥å…·åˆ—è¡¨
    model,
    {
      agentType: "chat-conversational-react-description",
      verbose: true, // æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
    }
  );

  // 3. è¿è¡Œ Agent
  console.log("\nğŸ“ æé—®: ä»€ä¹ˆæ˜¯ AI Agentï¼Ÿ\n");
  const response = await agent.invoke({
    input: "ç”¨ç®€å•çš„è¯è§£é‡Šä»€ä¹ˆæ˜¯ AI Agentï¼Œä¸è¶…è¿‡100å­—",
  });

  console.log("\nâœ… å›ç­”:");
  console.log(response.output);
  console.log("\n" + "=".repeat(50));
}

// è¿è¡Œç¤ºä¾‹
runBasicAgent().catch(console.error);
